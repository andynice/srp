{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7cc64dab45e34a1dbdb16f37cf78d6ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_736308bf0dd3433c91a434c04dd15ab6",
              "IPY_MODEL_c896027e5e35487eb79757e26043d081",
              "IPY_MODEL_bc30106068034a9bbcc7542a588bb149"
            ],
            "layout": "IPY_MODEL_e45b8fcac67f4e829b5e9ebb9c3c4394"
          }
        },
        "736308bf0dd3433c91a434c04dd15ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32b41ffef2a0423785587ce9e4bee31f",
            "placeholder": "​",
            "style": "IPY_MODEL_7f6e37e881d64ee099bdb464ebd378d6",
            "value": "Map:  38%"
          }
        },
        "c896027e5e35487eb79757e26043d081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_006a93ede8664c8f9fb44da2b0c35754",
            "max": 21,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f657045253aa498481ecbc772448645b",
            "value": 8
          }
        },
        "bc30106068034a9bbcc7542a588bb149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1637ba8d8879420ba6bf5252d5333657",
            "placeholder": "​",
            "style": "IPY_MODEL_61c4d8cc10a54bfa99bea3939974d684",
            "value": " 8/21 [04:40&lt;07:47, 35.98s/ examples]"
          }
        },
        "e45b8fcac67f4e829b5e9ebb9c3c4394": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32b41ffef2a0423785587ce9e4bee31f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f6e37e881d64ee099bdb464ebd378d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "006a93ede8664c8f9fb44da2b0c35754": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f657045253aa498481ecbc772448645b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1637ba8d8879420ba6bf5252d5333657": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61c4d8cc10a54bfa99bea3939974d684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pn00Qm1w5BG",
        "outputId": "32e3353d-25bf-4495-ecb8-c6a0a12275d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chDEDDqcx5hC",
        "outputId": "5b88bf4e-b711-46f5-d4aa-2661e5e277e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.14.5 dill-0.3.7 multiprocess-0.70.15 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNjqbL_slBze",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7cc64dab45e34a1dbdb16f37cf78d6ca",
            "736308bf0dd3433c91a434c04dd15ab6",
            "c896027e5e35487eb79757e26043d081",
            "bc30106068034a9bbcc7542a588bb149",
            "e45b8fcac67f4e829b5e9ebb9c3c4394",
            "32b41ffef2a0423785587ce9e4bee31f",
            "7f6e37e881d64ee099bdb464ebd378d6",
            "006a93ede8664c8f9fb44da2b0c35754",
            "f657045253aa498481ecbc772448645b",
            "1637ba8d8879420ba6bf5252d5333657",
            "61c4d8cc10a54bfa99bea3939974d684"
          ]
        },
        "outputId": "dbeec908-773c-43a7-efdd-d9bc3d874620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "1\n",
            "0\n",
            "<torch.cuda.device object at 0x7ff21849e320>\n",
            "Tesla T4\n",
            "X.shape: (31, 2)\n",
            "X.head():    created_at                                       clean_tweets\n",
            "0  2021-01-01  mf doom passed favourite shop covid casualty i...\n",
            "1  2021-01-02  vocal role head covid task force told people w...\n",
            "2  2021-01-03  love grandma burdensome think people overweigh...\n",
            "3  2021-01-04  covid leave hospital facing staffing issue sta...\n",
            "4  2021-01-05  covid protocol net star unavailable week detai...\n",
            "train_df\n",
            "train_df.shape: (21, 5)\n",
            "    created_at                                       clean_tweets        date  \\\n",
            "0   2021-01-01  mf doom passed favourite shop covid casualty i...  2021-01-01   \n",
            "1   2021-01-02  vocal role head covid task force told people w...  2021-01-02   \n",
            "2   2021-01-03  love grandma burdensome think people overweigh...  2021-01-03   \n",
            "3   2021-01-04  covid leave hospital facing staffing issue sta...  2021-01-04   \n",
            "4   2021-01-05  covid protocol net star unavailable week detai...  2021-01-05   \n",
            "5   2021-01-06  sod covid denier economic forecast project upd...  2021-01-06   \n",
            "6   2021-01-07  health worker family appeal covid suspended co...  2021-01-07   \n",
            "7   2021-01-08  expert tell indonesian authority transparent h...  2021-01-08   \n",
            "8   2021-01-09  spark workplace lawsuit read article dude covi...  2021-01-09   \n",
            "9   2021-01-10  gracewriters website christian writer covid pa...  2021-01-10   \n",
            "10  2021-01-11  definitively doordash driver earlier day left ...  2021-01-11   \n",
            "11  2021-01-12  care mom cured covid test thought mf covid bye...  2021-01-12   \n",
            "12  2021-01-13  customer service desk village square leisure c...  2021-01-13   \n",
            "13  2021-01-14  officially pandemic case bangladesh stand deat...  2021-01-14   \n",
            "14  2021-01-15  legislator told quarantine potential coronavir...  2021-01-15   \n",
            "15  2021-01-16  cure epilepsy posted epilepsy covid investigat...  2021-01-16   \n",
            "16  2021-01-17  feeling today covid brain fog lifted temporari...  2021-01-17   \n",
            "17  2021-01-18  covid covid germ growing food stopping germ gr...  2021-01-18   \n",
            "18  2021-01-19  helped pissed af colleague pushing wear mask i...  2021-01-19   \n",
            "19  2021-01-20  trump starting war encouraging war shouldve st...  2021-01-20   \n",
            "20  2021-01-21  covid violation team play pittsburgh annoying ...  2021-01-21   \n",
            "\n",
            "    total_cases   g_values  \n",
            "0     347003652   0.791591  \n",
            "1     430486198  24.058117  \n",
            "2     476865404  10.773680  \n",
            "3     538539241  12.933175  \n",
            "4     631097849  17.186976  \n",
            "5     713459493  13.050535  \n",
            "6     759671801   6.477215  \n",
            "7     825922069   8.720907  \n",
            "8     906405136   9.744632  \n",
            "9     971537392   7.185777  \n",
            "10   1027455520   5.755633  \n",
            "11   1094970203   6.571057  \n",
            "12    381899652 -65.122370  \n",
            "13    384476531   0.674753  \n",
            "14    387025106   0.662869  \n",
            "15    389545480   0.651217  \n",
            "16    395274029   1.470573  \n",
            "17    397432228   0.546001  \n",
            "18    399342968   0.480771  \n",
            "19    401280235   0.485114  \n",
            "20    403397878   0.527722  \n",
            "val_df\n",
            "val_df.shape: (5, 5)\n",
            "    created_at                                       clean_tweets        date  \\\n",
            "21  2021-01-22  order mask traveller quarantine covid fight pr...  2021-01-22   \n",
            "22  2021-01-23  watched local london news covid denier lost yr...  2021-01-23   \n",
            "23  2021-01-24  father covid interned week finally happy final...  2021-01-24   \n",
            "24  2021-01-25  government covid vaccine east auto news covid ...  2021-01-25   \n",
            "25  2021-01-26  president bolsonaros vocal critic maranho gove...  2021-01-26   \n",
            "\n",
            "    total_cases  g_values  \n",
            "21    405661934  0.561246  \n",
            "22    407819916  0.531966  \n",
            "23    413093354  1.293080  \n",
            "24    414932859  0.445300  \n",
            "25    416485013  0.374074  \n",
            "test_df\n",
            "test_df.shape: (5, 5)\n",
            "    created_at                                       clean_tweets        date  \\\n",
            "26  2021-01-27  doctor lying death certificate criminal offenc...  2021-01-27   \n",
            "27  2021-01-28  epidemiological evidence continues physical ac...  2021-01-28   \n",
            "28  2021-01-29  united soldier eritrea leave ethiopia embattle...  2021-01-29   \n",
            "29  2021-01-30  doesnt california covid case forget germany ba...  2021-01-30   \n",
            "30  2021-01-31  lie gas video evidence ab goverment charge fee...  2021-01-31   \n",
            "\n",
            "    total_cases  g_values  \n",
            "26    418219761  0.416521  \n",
            "27    420174711  0.467446  \n",
            "28    422195755  0.481001  \n",
            "29    424140324  0.460585  \n",
            "30    428869316  1.114959  \n",
            "Maximum input sequence length: 1000000000000000019884624838656\n",
            "ds\n",
            "{'train': Dataset({\n",
            "    features: ['created_at', 'clean_tweets', 'date', 'total_cases', 'g_values', '__index_level_0__'],\n",
            "    num_rows: 21\n",
            "}), 'validation': Dataset({\n",
            "    features: ['created_at', 'clean_tweets', 'date', 'total_cases', 'g_values', '__index_level_0__'],\n",
            "    num_rows: 5\n",
            "}), 'test': Dataset({\n",
            "    features: ['created_at', 'clean_tweets', 'date', 'total_cases', 'g_values', '__index_level_0__'],\n",
            "    num_rows: 5\n",
            "})}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/21 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7cc64dab45e34a1dbdb16f37cf78d6ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 1049, 2546, 12677, 2979, 8837, 4497, 2522, 17258, 19844, 5665, 4769, 16405, 2015, 5665, 4119, 2522, 17258, 4737, 2522, 17258, 11891, 6887, 27292, 6305, 2923, 4727, 9846, 9998, 2522, 17258, 17404, 6603, 17752, 3039, 3347, 4825, 2095, 6574, 5899, 2057, 3726, 2136, 6325, 2344, 4994, 2248, 2739, 4034, 6838, 20710, 4939, 2351, 2522, 17258, 2995, 2995, 3246, 16360, 6175, 20710, 4939, 20735, 3519, 4352, 4148, 6926, 3793, 9359, 2522, 17258, 4013, 2522, 17258, 2317, 2160, 4366, 8398, 22301, 3477, 3021, 3477, 4189, 3745, 5023, 4171, 11633, 3129, 2987, 2102, 4714, 2192, 2377, 5439, 8971, 2522, 17258, 8971, 2449, 6090, 3207, 7712, 25537, 19002, 7309, 8211, 2439, 3105, 3318, 3036, 5738, 16393, 16582, 24501, 26029, 5332, 6321, 4497, 24447, 2490, 4189, 2121, 5929, 3068, 3647, 3407, 2095, 2522, 17258, 17710, 2063, 7475, 5292, 11335, 4757, 3648, 9871, 7309, 4287, 3407, 17207, 2480, 7205, 2902, 6951, 2522, 17258, 3131, 4148, 24955, 2522, 17258, 6526, 2711, 2439, 3105, 2711, 2351, 2522, 17258, 14804, 2522, 17258, 9788, 2489, 11845, 3204, 2739, 13307, 2522, 17258, 21210, 3858, 5587, 3424, 8398, 3789, 17183, 2015, 27427, 2072, 3382, 8398, 18991, 5444, 2630, 9038, 3601, 4658, 2522, 17258, 5419, 2522, 17258, 4019, 2293, 2479, 2732, 23564, 2527, 7935, 4727, 10574, 16893, 6898, 7718, 3893, 2522, 17258, 16893, 2651, 6016, 2245, 21209, 7497, 13541, 2444, 7404, 6230, 2684, 2310, 6593, 12322, 7646, 1060, 18349, 2850, 2444, 3796, 18995, 10686, 7570, 13102, 2293, 2769, 2522, 17258, 9004, 3089, 9841, 14932, 2522, 17258, 8257, 21887, 2051, 2522, 17258, 5637, 3348, 3423, 21887, 7865, 4911, 5273, 6887, 27292, 6305, 2923, 15734, 9868, 9998, 17404, 4727, 6317, 2354, 19582, 9998, 11809, 4788, 9349, 4895, 2243, 19779, 15787, 2915, 9969, 9868, 17404, 2345, 3178, 2643, 29278, 3736, 7520, 2095, 4033, 2102, 17837, 24475, 5313, 15091, 23438, 4215, 14077, 2315, 10465, 2137, 25610, 2497, 2208, 14475, 16914, 5910, 2208, 5095, 10289, 8214, 14475, 9373, 7308, 11405, 7528, 2281, 12646, 3333, 2986, 18558, 5604, 3143, 7087, 23739, 10222, 2912, 2522, 17258, 2733, 4716, 2522, 17258, 4829, 4147, 7308, 2522, 17258, 3659, 14098, 2303, 7308, 5547, 3659, 3475, 2102, 7596, 2671, 2454, 2111, 3697, 23815, 27486, 5450, 2522, 17258, 16840, 5787, 2095, 7401, 3893, 2522, 17258, 3893, 3893, 2522, 17258, 3231, 2994, 3893, 2551, 2170, 3095, 2266, 2522, 17258, 2134, 2102, 11757, 5164, 4765, 5843, 7698, 3668, 5892, 2522, 17258, 2057, 3726, 7917, 2248, 3604, 9975, 4758, 3161, 2553, 3204, 3675, 2522, 17258, 6589, 2843, 4079, 3062, 3560, 10474, 2843, 2933, 19350, 2522, 17258, 6135, 21746, 2759, 2225, 3023, 3347, 2485, 2155, 2266, 3095, 2121, 3231, 3893, 2522, 17258, 8038, 11057, 11057, 4710, 2100, 2100, 2100, 2100, 2100, 2100, 2100, 2100, 2100, 2100, 2100, 2100, 2100, 2522, 17258, 4485, 1050, 2615, 2213, 8439, 2095, 2522, 17258, 4931, 2522, 17258, 10720, 2621, 9743, 2595, 11756, 5362, 18168, 2290, 21887, 23350, 4553, 4139, 6879, 6494, 2361, 8954, 2769, 2147, 6211, 7912, 5697, 2606, 2522, 17258, 3825, 10885, 26980, 3477, 23151, 22781, 2095, 3319, 5930, 3191, 23151, 5428, 7741, 3068, 13258, 2094, 3679, 14764, 3653, 2522, 17258, 2976, 4314, 2231, 11515, 2120, 7016, 6420, 2094, 15074, 2522, 17258, 19396, 3524, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'label': 0.791591107051089}\n",
            "{'input_ids': [101, 5554, 2535, 2132, 2522, 17258, 4708, 2486, 2409, 2111, 4929, 7308, 7374, 4400, 14286, 3292, 3891, 3105, 2111, 2166, 26478, 8609, 8898, 3533, 7226, 2368, 3377, 13373, 4148, 2193, 8985, 27218, 6075, 2164, 10327, 4786, 1048, 25219, 4295, 2522, 17258, 2553, 27218, 2405, 2255, 2095, 8985, 2733, 2141, 2522, 17258, 2315, 2522, 10736, 27634, 9689, 3942, 2155, 8970, 5816, 3666, 2694, 2154, 2051, 2343, 3105, 3246, 2522, 17258, 2193, 6183, 17404, 4897, 5833, 2486, 10041, 6186, 17404, 7308, 3191, 10392, 3203, 4070, 2522, 17258, 2358, 2726, 2522, 15185, 6038, 10041, 4013, 15509, 20370, 11704, 9714, 3399, 13905, 2111, 5236, 11047, 7898, 8439, 5315, 3932, 2437, 4489, 4553, 14622, 9313, 3265, 3946, 14495, 2400, 8825, 6769, 2522, 17258, 6090, 3207, 7712, 18921, 19763, 2078, 10194, 2641, 2400, 14600, 9313, 2111, 2366, 2451, 11562, 4553, 3265, 14495, 4900, 4374, 4664, 3946, 3282, 10887, 8361, 9151, 3068, 7802, 2522, 17258, 2051, 2283, 17612, 2522, 17258, 3627, 13260, 2522, 17258, 4829, 5676, 3696, 3820, 2522, 17258, 4033, 2102, 2657, 2764, 2933, 16062, 2522, 17258, 17404, 1056, 3654, 3946, 6226, 6851, 6134, 4374, 6697, 3189, 3132, 3979, 6289, 6633, 8742, 2389, 6396, 2102, 3189, 17663, 5378, 9474, 3466, 5154, 2642, 15250, 9015, 18888, 3060, 2137, 2767, 12448, 19055, 2733, 2522, 17258, 2095, 2095, 17015, 2318, 5306, 4485, 2095, 2522, 17258, 21746, 2843, 2933, 17015, 4276, 5580, 2777, 2293, 2166, 1059, 11039, 5025, 6616, 3124, 5881, 2282, 2137, 9015, 2522, 17258, 7865, 6346, 3105, 4468, 7173, 7752, 3745, 7123, 11890, 3593, 7349, 19629, 18939, 13775, 19797, 2278, 2546, 18939, 2063, 12480, 6415, 4726, 3124, 6383, 2171, 4489, 3663, 2381, 15192, 3475, 2102, 2193, 9217, 4066, 8568, 5432, 4772, 3267, 13685, 7151, 7865, 16130, 5981, 19188, 2470, 6845, 21887, 23350, 18906, 2015, 1999, 25969, 2529, 3526, 16494, 7055, 2281, 2415, 4295, 2491, 9740, 9362, 2522, 17258, 17404, 8989, 3085, 3808, 21150, 3816, 4031, 2186, 16330, 7987, 10288, 4183, 4485, 10583, 2522, 17258, 7217, 5305, 7406, 2135, 23624, 14289, 26255, 4297, 25377, 12870, 3372, 2051, 2522, 17258, 2553, 2623, 3475, 2102, 4569, 8239, 2643, 17130, 22930, 2051, 6739, 5632, 4251, 19593, 4847, 5816, 27885, 28817, 15780, 22891, 16926, 21887, 23350, 6090, 3207, 7712, 7400, 6819, 13153, 22522, 4958, 5178, 4328, 8662, 7155, 3769, 3226, 13675, 21104, 4284, 5409, 3099, 2637, 2976, 3648, 8040, 2953, 2818, 18079, 19031, 3775, 2053, 6633, 2522, 17258, 3433, 3860, 25353, 27718, 9626, 4588, 2522, 17258, 2204, 2801, 2082, 2128, 15222, 8950, 2075, 9312, 2126, 12504, 5335, 3076, 22219, 4958, 2118, 4361, 10115, 22132, 2080, 2000, 7068, 12849, 12514, 2937, 2696, 14270, 21981, 2137, 2351, 2522, 17258, 2501, 2193, 24735, 26629, 11310, 2137, 3280, 2522, 17258, 2733, 2111, 2975, 21887, 2522, 17258, 7865, 2393, 9436, 10041, 6429, 17688, 2100, 21887, 23350, 4785, 2689, 3102, 2111, 2769, 2785, 8235, 4106, 2716, 9518, 5870, 14758, 2331, 4057, 3061, 2600, 3673, 4130, 3554, 2522, 17258, 2111, 6015, 8959, 26212, 3593, 18087, 11512, 3482, 2095, 2522, 17258, 2071, 3726, 2904, 7865, 24501, 12514, 2229, 3088, 3460, 3571, 5409, 2259, 2051, 2111, 2553, 7215, 6230, 2406, 2193, 2103, 2095, 3584, 7215, 2111, 3236, 2388, 2375, 7718, 3893, 2522, 17258, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'label': 24.0581174056347}\n",
            "{'input_ids': [101, 2293, 13055, 10859, 14045, 2228, 2111, 2058, 11179, 2522, 17258, 2111, 15629, 2241, 2739, 2466, 2236, 6026, 18982, 2100, 2470, 17704, 2524, 13055, 2376, 10433, 5376, 13007, 2522, 17258, 3231, 13109, 2522, 17258, 2553, 2684, 2307, 7833, 2733, 3203, 3129, 2351, 2733, 2430, 20819, 2221, 3516, 5078, 7308, 2192, 2624, 25090, 6290, 2591, 3292, 2094, 13532, 3043, 9874, 22031, 2270, 2082, 2784, 7406, 11443, 4138, 3532, 4845, 5161, 2797, 2082, 4139, 3076, 2270, 2082, 22260, 10735, 5875, 13718, 2111, 2351, 2181, 26674, 2522, 17258, 2540, 2155, 2111, 2406, 5299, 4468, 13614, 2111, 7205, 3357, 6014, 4047, 8211, 2717, 9201, 10727, 8235, 2933, 2522, 17258, 7336, 6187, 4726, 2111, 9201, 4111, 21887, 5738, 2303, 2221, 6319, 6134, 17404, 6098, 3225, 6928, 2254, 14674, 9544, 4071, 7691, 3446, 2522, 17258, 2919, 3147, 2522, 17258, 17491, 2514, 6230, 3611, 5236, 8038, 7823, 7823, 2121, 2522, 17258, 16780, 3571, 3571, 8040, 3286, 5458, 2522, 17258, 6554, 2332, 24735, 2522, 17258, 7569, 2134, 2102, 4952, 14248, 2283, 2716, 12369, 2995, 8401, 4507, 5254, 11226, 2522, 17258, 2522, 17258, 2522, 17258, 10657, 2954, 21887, 23350, 4247, 11844, 9565, 13081, 2221, 7172, 2951, 2237, 3902, 2740, 7285, 2961, 2986, 10468, 5993, 5980, 4974, 3653, 2015, 21887, 10250, 2072, 2933, 3231, 8444, 5372, 3115, 8375, 5057, 2373, 2474, 8398, 8984, 3524, 3266, 3988, 4400, 3407, 2522, 17258, 3231, 4997, 3305, 5665, 19857, 2915, 2522, 17258, 4957, 3160, 24119, 3743, 11524, 21887, 23350, 10651, 4465, 2254, 4154, 21887, 9238, 2693, 2522, 17258, 2862, 2804, 11753, 2218, 2829, 2829, 9560, 4474, 7718, 3893, 2220, 2285, 6603, 2019, 11236, 7274, 2213, 2341, 11429, 6635, 7483, 3271, 10771, 6114, 2522, 17258, 2409, 2402, 4608, 7865, 18173, 18173, 3043, 2287, 8398, 4945, 3480, 6554, 2332, 2522, 17258, 5305, 7406, 2351, 2933, 6090, 3207, 7712, 10723, 3304, 3189, 21887, 23350, 2331, 5095, 2553, 2522, 17258, 3113, 6221, 8398, 3478, 4047, 3076, 2522, 17258, 2522, 17258, 2617, 2514, 10350, 2686, 2980, 2707, 24663, 5637, 2522, 17258, 12532, 3608, 2522, 17258, 2331, 6517, 10047, 4168, 28329, 3265, 14038, 2128, 2102, 28394, 3215, 3167, 4847, 3110, 3279, 3915, 2522, 17258, 2331, 2406, 2972, 2522, 17258, 16291, 3110, 6898, 2767, 1053, 6392, 2154, 6595, 7364, 8293, 3047, 7842, 4161, 2980, 13102, 4140, 4997, 2522, 17258, 3231, 24209, 20486, 10196, 2134, 2102, 5305, 5458, 14337, 2004, 2111, 6090, 3207, 7712, 2524, 21873, 2402, 2111, 10468, 4671, 12771, 2522, 17258, 8985, 6687, 15310, 22787, 5458, 2095, 2307, 17626, 2522, 17258, 2718, 2166, 2524, 3246, 3997, 10930, 3404, 2767, 2166, 2293, 3407, 2095, 2522, 17258, 6809, 21887, 23350, 17404, 6749, 2740, 4034, 19428, 2866, 2739, 3712, 2739, 8336, 7842, 2912, 2061, 16093, 21031, 2522, 17258, 2522, 17258, 2695, 29513, 3672, 3114, 6847, 2447, 3749, 2391, 6232, 5562, 2111, 5770, 9359, 2769, 4686, 4189, 3062, 10450, 2080, 4148, 2111, 8980, 2522, 17258, 2613, 2540, 2886, 10572, 2354, 3749, 2347, 2102, 2522, 17258, 6821, 9361, 3772, 3565, 3671, 2522, 17258, 5776, 9398, 5844, 6091, 6069, 5845, 2058, 16416, 11873, 29310, 2278, 2338, 8814, 4819, 21887, 23350, 7691, 6410, 7374, 6090, 3207, 7712, 24209, 20486, 10196, 13316, 4492, 2522, 17258, 3179, 3475, 2102, 3403, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'label': 10.7736801355011}\n",
            "{'input_ids': [101, 2522, 17258, 2681, 2902, 5307, 3095, 2075, 3277, 3095, 8046, 3062, 5665, 23956, 12058, 2522, 17258, 5776, 2357, 2522, 17258, 2430, 3246, 28305, 5788, 21887, 23350, 7912, 2522, 17258, 3893, 7672, 3789, 2160, 2723, 2986, 7672, 3484, 2311, 21887, 12436, 26013, 2015, 2613, 6904, 14194, 2072, 15454, 8398, 4366, 21887, 23350, 2331, 2058, 3597, 16671, 2098, 7272, 3761, 5993, 19220, 4638, 5088, 2873, 2437, 5409, 2377, 2655, 5920, 8897, 2522, 17258, 2331, 2767, 6904, 2213, 3659, 8318, 2278, 14181, 2050, 26487, 9803, 2181, 24471, 13250, 4523, 5341, 23689, 6659, 4400, 2739, 5169, 3189, 2358, 2553, 21887, 23350, 10178, 4453, 2522, 17258, 2313, 2553, 2553, 2331, 2331, 2331, 3446, 5553, 2522, 17258, 10372, 2111, 2902, 8991, 10085, 16975, 25047, 6221, 8398, 7226, 2368, 2928, 8398, 2051, 2436, 2277, 4330, 2422, 3342, 2439, 2180, 2102, 8014, 2009, 3363, 11178, 8339, 3842, 2783, 2522, 17258, 3291, 2359, 9359, 8275, 2739, 8840, 2140, 13946, 2522, 17258, 3475, 2102, 3622, 6359, 2540, 2886, 6909, 19802, 6190, 1046, 21030, 4371, 11248, 4831, 4557, 9610, 6155, 7118, 4019, 5843, 7698, 2522, 17258, 13675, 10085, 8962, 2522, 17258, 2146, 2822, 8240, 3189, 4484, 2522, 17258, 2553, 27143, 11860, 10964, 10488, 2705, 5302, 24920, 9734, 2015, 2775, 21887, 7865, 10651, 3280, 2075, 2919, 2460, 2391, 14636, 3407, 5798, 2524, 2954, 2111, 4485, 6773, 2793, 5254, 2522, 17258, 2346, 2863, 2361, 2950, 7865, 2315, 2522, 17258, 2337, 2877, 3020, 13356, 3446, 24582, 3489, 2231, 2933, 3749, 1057, 5638, 15091, 6651, 2709, 6926, 2561, 22645, 9155, 2139, 6914, 18702, 6723, 2396, 2338, 10125, 26243, 2080, 6432, 7233, 2522, 17258, 2522, 17258, 5292, 3270, 2522, 6895, 2094, 11867, 13775, 2075, 2522, 17258, 17490, 7173, 4788, 2522, 17258, 2299, 2152, 3246, 6634, 12532, 2522, 17258, 2733, 2051, 5510, 5437, 2347, 2102, 2051, 4831, 6232, 10057, 2111, 6209, 4468, 2522, 17258, 5843, 7698, 6687, 2787, 2522, 17258, 3893, 2193, 2152, 3836, 6570, 19512, 9823, 4808, 19807, 12273, 14451, 5776, 2522, 17258, 5236, 5463, 3565, 13102, 16416, 4063, 2724, 2111, 27937, 2072, 2309, 2711, 4132, 6626, 4071, 2919, 2391, 8339, 3271, 5587, 2331, 4921, 2063, 2522, 17258, 4921, 2063, 2154, 2204, 2186, 20907, 3539, 2085, 9189, 12832, 2307, 21887, 23350, 17404, 7610, 24273, 2702, 2454, 14855, 2497, 2258, 23281, 2017, 3726, 3204, 5665, 2522, 17258, 17404, 3124, 4642, 2239, 17727, 5243, 7690, 2439, 2602, 4429, 8126, 21887, 3433, 2439, 2702, 9870, 22653, 1059, 20535, 3070, 2602, 2978, 8673, 14684, 8737, 5292, 3270, 3270, 20976, 12489, 4429, 2243, 2502, 2051, 8840, 2140, 8085, 2154, 2307, 2707, 2693, 3435, 2895, 7483, 18792, 2075, 2651, 3154, 3443, 3154, 5204, 3619, 2015, 3049, 2775, 4839, 2204, 3160, 2134, 2102, 2522, 17258, 17404, 3280, 7308, 2147, 4147, 5236, 2231, 7308, 14770, 2082, 2244, 2876, 2102, 6752, 2522, 17258, 3663, 6133, 3085, 4831, 4557, 4465, 10033, 2111, 6209, 4019, 21887, 23350, 5843, 7698, 2734, 3618, 7073, 6114, 3204, 8536, 7865, 2491, 5245, 2709, 14230, 3653, 26775, 17417, 2015, 2504, 3204, 2051, 4099, 2166, 24585, 2231, 10862, 8394, 3124, 2490, 3962, 2343, 4456, 3280, 2482, 5823, 3280, 4456, 2482, 5823, 2482, 5823, 10094, 2522, 17258, 2482, 5823, 2522, 17258, 2522, 17258, 2258, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'label': 12.9331749551704}\n",
            "{'input_ids': [101, 2522, 17258, 8778, 5658, 2732, 20165, 2733, 6987, 1056, 28394, 2102, 14026, 25805, 22717, 13879, 2155, 2343, 2281, 8398, 3214, 2522, 17258, 10436, 2602, 2522, 17258, 13228, 10372, 22052, 2522, 17258, 6187, 2290, 2860, 10366, 3795, 5081, 5478, 4800, 11457, 2561, 25691, 5576, 3795, 5130, 4372, 14540, 10696, 2553, 2866, 8349, 10178, 2988, 2670, 2662, 3099, 5987, 2866, 2522, 17258, 15527, 3659, 24663, 3915, 11807, 1056, 28394, 2102, 1056, 28394, 2102, 5460, 3291, 2270, 2740, 2522, 17258, 2330, 2791, 16987, 10372, 12436, 2595, 2437, 2111, 6839, 2522, 17258, 19857, 2915, 5448, 3752, 2111, 3304, 19857, 2915, 2522, 17258, 25353, 27718, 5358, 23653, 3178, 24665, 10128, 3436, 8701, 4688, 2522, 17258, 4400, 2522, 17258, 5396, 12832, 2277, 2329, 3539, 2704, 11235, 3779, 3641, 2733, 9053, 21887, 23350, 5843, 7698, 9606, 8655, 5289, 9384, 3627, 28101, 8349, 3659, 2522, 17258, 3659, 2121, 2724, 2733, 7269, 14300, 2015, 4345, 2004, 6494, 10431, 19281, 2522, 17258, 17404, 5057, 3178, 2146, 3405, 2343, 3772, 19582, 2775, 3313, 4637, 19383, 2522, 17258, 2281, 2111, 5996, 2111, 8536, 2966, 6098, 24992, 2094, 2331, 17612, 2522, 17258, 4521, 4485, 8738, 4288, 4083, 11997, 6911, 2522, 17258, 6090, 3207, 7712, 6911, 2514, 10827, 4553, 5047, 6090, 3207, 7712, 6911, 7965, 9927, 7714, 3102, 2522, 17258, 7367, 23194, 6313, 2895, 10339, 29530, 6396, 8725, 4637, 8398, 2095, 5094, 13794, 2522, 17258, 2895, 2717, 2283, 3303, 3255, 2540, 15395, 2246, 12992, 2075, 5356, 4834, 2437, 2522, 17258, 4171, 5468, 3828, 14337, 2004, 2522, 17258, 2707, 3110, 11059, 2221, 7173, 24467, 2553, 2522, 17258, 22410, 2146, 3309, 24209, 20486, 10196, 19616, 6475, 4903, 2140, 6133, 2565, 4903, 2140, 3693, 10967, 2270, 2326, 4638, 21862, 2854, 21877, 10483, 2072, 2522, 17258, 3893, 2160, 2266, 3789, 2180, 3789, 4736, 3422, 3246, 10947, 3811, 9530, 15900, 6313, 10178, 2522, 17258, 10416, 4691, 2312, 2103, 3023, 2028, 8524, 2522, 17258, 6928, 2254, 2553, 3161, 2553, 2561, 2553, 2331, 2561, 2331, 2902, 3989, 7409, 2689, 2167, 7734, 18079, 10979, 5463, 4402, 1059, 12617, 7484, 3467, 3116, 10537, 3857, 7965, 17026, 3541, 2451, 3422, 3191, 28667, 9331, 3116, 5987, 2522, 17258, 5776, 7120, 7120, 2902, 3403, 2282, 4829, 5024, 2095, 2522, 17258, 3614, 4330, 10041, 7120, 7467, 8814, 4819, 5236, 2994, 7965, 19857, 2161, 6090, 3207, 7712, 2852, 6662, 21701, 14898, 17917, 2361, 2708, 2966, 2961, 3745, 4236, 7484, 2724, 3942, 21887, 23350, 4363, 2111, 2551, 21887, 7501, 21358, 2522, 17258, 18168, 2290, 9964, 9585, 3076, 2118, 2702, 11656, 3820, 2220, 2522, 17258, 4647, 2231, 3154, 2095, 2522, 27794, 3742, 12436, 14693, 9323, 3246, 2933, 3475, 2102, 3844, 3634, 4595, 13732, 27322, 8991, 8991, 2095, 4699, 22067, 3693, 2522, 17258, 8258, 4512, 24209, 16012, 27179, 2015, 8267, 4804, 2522, 17258, 9740, 3949, 2470, 24209, 2015, 10047, 23041, 14573, 6906, 7685, 4132, 2166, 5552, 6687, 2905, 5341, 5175, 2522, 17258, 4990, 11429, 23181, 2137, 10107, 3984, 17404, 27263, 2544, 5444, 2695, 23068, 2050, 3455, 2873, 4116, 8076, 7729, 3204, 2095, 2522, 17258, 19857, 2193, 22410, 3433, 15011, 2522, 17258, 14181, 9468, 3075, 3613, 6727, 7814, 6090, 3207, 7712, 2994, 3647, 7965, 2365, 2082, 2633, 11703, 2522, 17258, 16939, 2170, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'label': 17.1869756098238}\n",
            "{'input_ids': [101, 2061, 2094, 2522, 17258, 7939, 3771, 3171, 19939, 2622, 10651, 2852, 9399, 27706, 5856, 27684, 2015, 6745, 2739, 2334, 4897, 5833, 2522, 17258, 17404, 2902, 3570, 2221, 8694, 9432, 7610, 4236, 27056, 11721, 27032, 6841, 2098, 2095, 2522, 17258, 9868, 26478, 8609, 2015, 1056, 3501, 2111, 5101, 2181, 3236, 2522, 17258, 3671, 4697, 5221, 2522, 17258, 6090, 3207, 7712, 4036, 2236, 2270, 2936, 13538, 3507, 6926, 2231, 7975, 18476, 4697, 7904, 4903, 2140, 3524, 27103, 9388, 2474, 3995, 14424, 2375, 2485, 9388, 2474, 3995, 3844, 2095, 6574, 2283, 14424, 2522, 17258, 3627, 2375, 8571, 3020, 19857, 2915, 3446, 15316, 4668, 2522, 17258, 17404, 24953, 27634, 2232, 4895, 3726, 12146, 2933, 10047, 23041, 4697, 2111, 3679, 2522, 17258, 9432, 9160, 2490, 2004, 7499, 2522, 17258, 28543, 2004, 1039, 8038, 3363, 1052, 12202, 3477, 5527, 3784, 21887, 23350, 9292, 15316, 4668, 2770, 3020, 21068, 17404, 4248, 21357, 3745, 2128, 2102, 28394, 2102, 9130, 5542, 2293, 6778, 5223, 4126, 3962, 1052, 2444, 4701, 2318, 4254, 2166, 24188, 4509, 3638, 8235, 3025, 2522, 17258, 2204, 3114, 9207, 2152, 3891, 5776, 2152, 5468, 2739, 5358, 2662, 4030, 16062, 21887, 23350, 17404, 5478, 2700, 2270, 2880, 3143, 2465, 2154, 6819, 13153, 15707, 6887, 27292, 22684, 6483, 16127, 2495, 2734, 2465, 3784, 2154, 7078, 8639, 2522, 17258, 8257, 8038, 3363, 2829, 2522, 17258, 15280, 8840, 2140, 3520, 8486, 5794, 8722, 3098, 2492, 2902, 2530, 2167, 3792, 7438, 2058, 12314, 5776, 6114, 21887, 23350, 4033, 2102, 9967, 2729, 3745, 3937, 2951, 5976, 18792, 9694, 3171, 4071, 2522, 17258, 2287, 4701, 6919, 2944, 6745, 8985, 3861, 2522, 17258, 3105, 2293, 5305, 3477, 5008, 7743, 2522, 17258, 2613, 3124, 2377, 2419, 2422, 3102, 21887, 23350, 17473, 2111, 9998, 21887, 23350, 17404, 4083, 8750, 14841, 25509, 6559, 3153, 3566, 14315, 21887, 3677, 17159, 13433, 11253, 8112, 4748, 10020, 2246, 14910, 2050, 14863, 2094, 5113, 8962, 2271, 1040, 2100, 2522, 17258, 3246, 1038, 2989, 4487, 5054, 17603, 5999, 4689, 2995, 17111, 9541, 2080, 3398, 3191, 2522, 17258, 24663, 6687, 9062, 1999, 14919, 2015, 12436, 14693, 23854, 2991, 4403, 2287, 10318, 4650, 5993, 3696, 6279, 11067, 7812, 10214, 2489, 10439, 26629, 11338, 2290, 3205, 4022, 7654, 2609, 2711, 3230, 2154, 8362, 2154, 3231, 7718, 3893, 21887, 23350, 3105, 6616, 7904, 2522, 17258, 15488, 2232, 3784, 4164, 8778, 2063, 5333, 2769, 2111, 8084, 2522, 17258, 1048, 2863, 2080, 7308, 29262, 7384, 2836, 6719, 5223, 3434, 6719, 9061, 5875, 2522, 17258, 11643, 2609, 6135, 9530, 21001, 6209, 16510, 2522, 17258, 17404, 22953, 2522, 17258, 4760, 2111, 2995, 6120, 10468, 4760, 2111, 19223, 2739, 5956, 2987, 2102, 2522, 17258, 2915, 2994, 3828, 8816, 7661, 21335, 3468, 2522, 17258, 3647, 2147, 7709, 2489, 17186, 2502, 2522, 17258, 3659, 9421, 2522, 17258, 20114, 3124, 3500, 5875, 4897, 5833, 4969, 4487, 11393, 27932, 23614, 11252, 2729, 5856, 6299, 10802, 2569, 15384, 22747, 2015, 2470, 15102, 6090, 3207, 7712, 4254, 4845, 2569, 2082, 2128, 15222, 8950, 2075, 9312, 2126, 12504, 5335, 3076, 22219, 4958, 2118, 4361, 10115, 22132, 2080, 2000, 7068, 12849, 12514, 2937, 2696, 14270, 2643, 19994, 2990, 6719, 2902, 2522, 17258, 2540, 4911, 2406, 17773, 2142, 2902, 2793, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'label': 13.0505347356999}\n",
            "{'input_ids': [101, 2740, 7309, 2155, 5574, 2522, 17258, 6731, 2873, 2522, 17258, 2862, 5798, 4003, 7960, 3485, 4558, 2276, 7301, 21340, 3259, 26300, 2522, 17258, 3921, 4752, 17404, 2933, 17404, 2522, 17258, 6634, 2522, 17258, 4465, 2851, 2326, 3784, 2254, 4803, 2522, 17258, 2553, 2221, 13746, 2711, 7215, 4465, 2254, 2522, 17258, 23848, 2050, 11798, 2187, 2617, 12930, 21887, 23350, 6090, 3207, 7712, 26047, 2350, 3277, 2637, 2651, 24552, 16311, 3010, 2522, 17258, 3325, 11599, 2793, 5327, 2137, 2767, 3647, 7359, 3199, 21887, 23350, 2522, 17258, 10651, 5009, 4179, 4125, 2522, 17258, 2331, 7108, 2111, 6809, 4234, 2558, 2553, 23069, 3012, 3102, 4171, 7374, 2099, 5371, 4171, 8536, 21887, 23350, 19220, 4638, 7359, 3199, 21887, 23350, 2522, 17258, 10651, 5009, 4179, 3398, 5001, 4691, 18079, 14636, 2522, 17258, 10398, 11891, 2378, 5003, 18879, 14841, 2102, 6616, 2378, 24547, 24065, 2099, 7359, 3199, 21887, 23350, 2522, 17258, 10651, 5009, 4179, 7359, 3199, 21887, 23350, 2522, 17258, 10651, 5009, 4179, 7359, 3199, 21887, 23350, 2522, 17258, 10651, 5009, 4179, 5983, 3256, 6949, 2103, 6402, 5440, 2522, 17258, 4023, 7359, 3199, 21887, 23350, 2522, 17258, 10651, 5009, 4179, 14199, 13610, 2862, 2311, 3023, 3023, 5402, 4130, 3171, 7057, 4737, 2202, 2843, 2943, 9530, 8043, 6455, 2943, 3145, 10368, 2051, 3579, 3893, 2491, 17111, 9541, 2522, 17258, 4748, 2232, 23283, 2553, 2522, 17258, 6751, 3623, 9857, 4034, 23283, 3176, 2331, 5026, 2561, 2193, 2331, 2651, 3231, 23596, 7473, 2099, 28873, 1038, 2213, 3501, 3602, 12436, 1999, 2063, 3979, 2881, 11487, 7312, 9560, 2902, 9634, 11806, 2729, 2331, 12436, 1999, 2229, 3273, 5646, 17938, 6726, 7865, 2406, 10107, 4167, 4171, 2769, 2987, 2102, 10107, 2695, 2522, 17258, 4060, 2173, 2681, 5796, 2213, 2425, 2437, 4551, 6475, 2522, 17258, 4551, 4795, 2522, 17258, 7499, 27105, 2602, 2095, 2146, 5843, 7698, 2522, 17258, 3571, 22555, 21447, 6402, 8840, 4140, 4028, 3424, 7011, 7404, 4697, 2111, 2621, 7499, 7490, 6555, 7672, 3788, 1044, 22571, 10085, 17625, 2377, 27202, 27568, 2254, 2439, 7564, 2111, 2522, 17258, 2051, 2522, 17258, 2919, 2204, 15589, 5376, 10825, 4788, 2326, 8985, 5039, 3613, 4070, 2922, 4664, 7637, 3085, 2553, 5522, 3517, 5057, 2555, 4539, 2833, 5069, 5858, 2522, 17258, 2331, 2988, 2651, 7961, 12033, 2522, 17258, 2331, 2331, 7017, 7308, 2591, 4487, 12693, 6129, 10142, 16714, 3290, 4026, 2422, 2739, 2254, 2662, 21887, 23350, 2193, 5719, 2061, 2906, 8922, 2400, 14475, 10323, 18451, 3490, 2651, 10651, 5204, 5901, 20607, 3663, 3613, 3745, 10651, 4553, 3232, 11320, 2140, 3538, 2522, 17258, 7308, 2057, 14277, 2533, 7949, 3343, 15080, 27326, 2961, 3618, 3389, 4576, 23701, 3726, 4357, 9095, 3191, 2293, 4756, 2734, 2613, 2147, 5069, 7966, 2522, 17258, 1052, 8873, 6290, 2715, 2050, 2444, 5646, 2522, 17258, 17404, 2405, 2204, 2739, 2489, 3298, 2522, 17258, 5604, 5553, 5581, 2843, 3653, 2890, 24063, 2121, 3942, 2522, 17258, 8293, 6230, 14870, 8579, 8962, 8320, 2075, 9424, 2474, 2542, 3984, 3255, 8040, 3286, 3691, 19052, 2966, 10802, 5776, 13595, 14203, 3231, 7709, 9861, 15608, 2111, 3477, 4979, 17404, 6727, 2522, 17258, 4930, 11573, 2326, 3140, 3844, 6429, 15009, 2341, 2330, 2366, 7954, 2522, 17258, 3291, 14280, 3997, 3638, 10126, 4708, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'label': 6.47721537850503}\n",
            "{'input_ids': [101, 6739, 2425, 9003, 3691, 13338, 11085, 2389, 10618, 17404, 3772, 11524, 4239, 2198, 22466, 8017, 2080, 4346, 2522, 17258, 10651, 2740, 2880, 2120, 5239, 3116, 26047, 2660, 17404, 4897, 5833, 2334, 2880, 2933, 7411, 21887, 23350, 3231, 2609, 2012, 9286, 12691, 2733, 3652, 8785, 20547, 26651, 7692, 5335, 5270, 8147, 6556, 20831, 2522, 17258, 17261, 6994, 6133, 6911, 2522, 17258, 16840, 2522, 17258, 2522, 17258, 11865, 13229, 2331, 28616, 11774, 2989, 2522, 17258, 2668, 2192, 5057, 4161, 2900, 9432, 9384, 5843, 7698, 19013, 2406, 2522, 17258, 5057, 3500, 4254, 3679, 2166, 7935, 3613, 3582, 26629, 7705, 8225, 4170, 3113, 9095, 2733, 2522, 17258, 10651, 6866, 2212, 4037, 4882, 10651, 3602, 2458, 2733, 2350, 8874, 10329, 16110, 9130, 9124, 4013, 3282, 3424, 2522, 17258, 4071, 8295, 2177, 2170, 12014, 2433, 21411, 3811, 16755, 2740, 2729, 3026, 2729, 2291, 9969, 2104, 11263, 25848, 2231, 2576, 18247, 5476, 10131, 2989, 10178, 2231, 16840, 2522, 17258, 3613, 2733, 2051, 2330, 9689, 2740, 6739, 3201, 5665, 6055, 5047, 2522, 17258, 8349, 10958, 3567, 4726, 2866, 2522, 17258, 8349, 16514, 2599, 2902, 3989, 2331, 3189, 3284, 2309, 2154, 2522, 17258, 2331, 9565, 2154, 3295, 23678, 2075, 2767, 7133, 2351, 2522, 17258, 4561, 8318, 2278, 7483, 4142, 4603, 4001, 3003, 5307, 2655, 12897, 10885, 3290, 2120, 4603, 3003, 3168, 11235, 3779, 2563, 2522, 17258, 5843, 7698, 2180, 2102, 9748, 4335, 19455, 2931, 3095, 2522, 17258, 27853, 2204, 5980, 2166, 2729, 2415, 7632, 4135, 9317, 2211, 12436, 14693, 19833, 2075, 6319, 7904, 2522, 17258, 5135, 19413, 2015, 16840, 2449, 3145, 10651, 21887, 23350, 3793, 4471, 3793, 21461, 2595, 3597, 17258, 3696, 3793, 10373, 2006, 28897, 2015, 2231, 2522, 17258, 12436, 14693, 9323, 10915, 2270, 5448, 5002, 6083, 11125, 2859, 7607, 5195, 6648, 2522, 17258, 8117, 2226, 2111, 2730, 2111, 5996, 2522, 17258, 8398, 4126, 2155, 2767, 3347, 2065, 2721, 21862, 4773, 3981, 2099, 2330, 3229, 3075, 10800, 2522, 17258, 4130, 2925, 24665, 5833, 2126, 4489, 2506, 2490, 2689, 2334, 2166, 2733, 9936, 2831, 2522, 17258, 17404, 17404, 2147, 2783, 3570, 12667, 2615, 2361, 4062, 3860, 3836, 2522, 17258, 15559, 6463, 25423, 2891, 2226, 7119, 2844, 3860, 2266, 6090, 3207, 7712, 8885, 21990, 10651, 10651, 6904, 4160, 8498, 10316, 2522, 17258, 5057, 3611, 3080, 2567, 2522, 17258, 2358, 5191, 2542, 3188, 2740, 3277, 2729, 2514, 4945, 2365, 2729, 4882, 2522, 17258, 10651, 17404, 2987, 2102, 4839, 2522, 17258, 8275, 9530, 15900, 6313, 2791, 8275, 2466, 3233, 5881, 2160, 14557, 2522, 17258, 2787, 24802, 2553, 18704, 10427, 4586, 2098, 2204, 3204, 4595, 7036, 2351, 4242, 3254, 3255, 2522, 17258, 7483, 8398, 7865, 10107, 2245, 4622, 17328, 8670, 10322, 12474, 3539, 2704, 3641, 2120, 2111, 2681, 2188, 3132, 3114, 5468, 3517, 2994, 2173, 3054, 2337, 2057, 3726, 5983, 2057, 2571, 2166, 4209, 2522, 17258, 17404, 6689, 2522, 2364, 4825, 15581, 2522, 17258, 3690, 21155, 5335, 8013, 3325, 2231, 2486, 21887, 23350, 17404, 2995, 2331, 8196, 2862, 2522, 17258, 3622, 10318, 2331, 12130, 2100, 5387, 3276, 2155, 3466, 2522, 17258, 5843, 7698, 2963, 3745, 2466, 2248, 2470, 3276, 2155, 3466, 2522, 17258, 5843, 7698, 2963, 3745, 2466, 2248, 2470, 2277, 3995, 2121, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'label': 8.72090656949369}\n"
          ]
        }
      ],
      "source": [
        "train_arg = True\n",
        "startDate = '2021-01-01'\n",
        "endDate = '2021-02-01'\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# from accelerate import Accelerator\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, AdamW, get_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from time import time\n",
        "\n",
        "# TRAIN OR EVAL\n",
        "train = train_arg\n",
        "trained_model_name = \"model_covid_twitter_bert_v2.model\"\n",
        "\n",
        "# MODEL DEFINITION\n",
        "if train:\n",
        "    # BASE_MODEL = \"digitalepidemiologylab/covid-twitter-bert\"\n",
        "    # BASE_MODEL = \"./covid-twitter-bert\"\n",
        "    BASE_MODEL = \"digitalepidemiologylab/covid-twitter-bert-v2\"\n",
        "    # BASE_MODEL = \"./covid-twitter-bert-v2\"\n",
        "else:\n",
        "    BASE_MODEL = \"/content/\" + trained_model_name\n",
        "LEARNING_RATE = 2e-5\n",
        "MAX_LENGTH = 512\n",
        "# BATCH_SIZE = 16\n",
        "BATCH_SIZE = 2\n",
        "EPOCHS = 3\n",
        "\n",
        "# accelerator = Accelerator()\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL, num_labels=1)\n",
        "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "print(torch.cuda.device_count())\n",
        "\n",
        "print(torch.cuda.current_device())\n",
        "\n",
        "print(torch.cuda.device(0))\n",
        "\n",
        "print(torch.cuda.get_device_name(0))\n",
        "\n",
        "# DATA PREPARATION\n",
        "\n",
        "g_cases_filename = f\"/content/data/g_cases_2021.csv\"\n",
        "y = pd.read_csv(g_cases_filename)\n",
        "\n",
        "X = pd.DataFrame()\n",
        "# date_ranges = [['2021-01-01', '2021-04-01']]\n",
        "# date_ranges = [['2020-01-01', '2020-01-12']]\n",
        "date_ranges = [[startDate, endDate]]\n",
        "for date_range in date_ranges:\n",
        "    start = datetime.datetime.strptime(date_range[0], \"%Y-%m-%d\")\n",
        "    end = datetime.datetime.strptime(date_range[1], \"%Y-%m-%d\")\n",
        "    date_generated = [start + datetime.timedelta(days=x) for x in range(0, (end - start).days)]\n",
        "\n",
        "    for date in date_generated:\n",
        "        date_str = date.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "        filename = f\"/content/data/en_{date_str}_output.csv\"\n",
        "        df_data = pd.read_csv(filename)\n",
        "        df_data = df_data.replace(r'^\\s*$', np.nan, regex=True)\n",
        "        #X = total_dataframe.append(df_data, ignore_index=True)\n",
        "        X = pd.concat([X, df_data], ignore_index=True)\n",
        "\n",
        "print(f\"X.shape: {X.shape}\")\n",
        "print(f\"X.head(): {X.head()}\")\n",
        "\n",
        "train_ratio = 0.70\n",
        "validation_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "# train is now 70% of the entire data set, test size 30%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_ratio, random_state=42, shuffle=False)\n",
        "#X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, train_size=0.7, random_state=42, shuffle=False)\n",
        "\n",
        "# test is now 15% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state=42, shuffle=False)\n",
        "train_df = pd.concat([X_train, y_train], axis=1)\n",
        "val_df = pd.concat([X_val, y_val], axis=1)\n",
        "test_df = pd.concat([X_test, y_test], axis=1)\n",
        "\n",
        "print(\"train_df\")\n",
        "print(f\"train_df.shape: {train_df.shape}\")\n",
        "print(train_df)\n",
        "\n",
        "print(\"val_df\")\n",
        "print(f\"val_df.shape: {val_df.shape}\")\n",
        "print(val_df)\n",
        "\n",
        "print(\"test_df\")\n",
        "print(f\"test_df.shape: {test_df.shape}\")\n",
        "print(test_df)\n",
        "\n",
        "raw_train_ds = Dataset.from_pandas(train_df)\n",
        "raw_val_ds = Dataset.from_pandas(val_df)\n",
        "raw_test_ds = Dataset.from_pandas(test_df)\n",
        "\n",
        "max_length = tokenizer.model_max_length\n",
        "print(\"Maximum input sequence length:\", max_length)\n",
        "# Maximum input sequence length: 1000000000000000019884624838656\n",
        "\n",
        "ds = {\"train\": raw_train_ds, \"validation\": raw_val_ds, \"test\": raw_test_ds}\n",
        "\n",
        "print(\"ds\")\n",
        "print(ds)\n",
        "\n",
        "# CALCULATE MAX_LENGTH\n",
        "# Tokenize all tweets to find the maximum tokenized length\n",
        "# max_length = 0\n",
        "\n",
        "# for index, row in X.iterrows():\n",
        "#     tweet = row['clean_tweets']\n",
        "\n",
        "#     # Tokenize the tweet\n",
        "#     tokens = tokenizer(tweet, return_tensors=\"pt\")\n",
        "\n",
        "#     # Get the length of the tokenized sequence\n",
        "#     length = tokens['input_ids'].shape[1]\n",
        "#     print(f\"current length: {length}\")\n",
        "\n",
        "#     # Update max_length if needed\n",
        "#     if length > max_length:\n",
        "#         max_length = length\n",
        "\n",
        "# print(f\"Calculated max_length: {max_length}\")\n",
        "# Model's max length\n",
        "# max_length = 512\n",
        "# RuntimeError: The size of tensor a (600) must match the size of tensor b (512) at non-singleton dimension 1\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    label = examples[\"g_values\"]\n",
        "    # examples = tokenizer(examples[\"clean_tweets\"], truncation=True, padding=\"max_length\", max_length=256)\n",
        "    # examples = tokenizer(examples[\"clean_tweets\"], truncation=False, padding=True, return_tensors=\"pt\")\n",
        "    examples = tokenizer(examples[\"clean_tweets\"], truncation=True, padding=\"max_length\", max_length=MAX_LENGTH)\n",
        "    # examples = tokenizer(examples[\"clean_tweets\"], truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # examples = tokenizer(examples[\"clean_tweets\"])\n",
        "\n",
        "    examples[\"label\"] = float(label)\n",
        "    # examples[\"label\"] = [float(i) for i in label]\n",
        "    print(examples)\n",
        "    return examples\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "if train:\n",
        "    ds[\"train\"] = ds[\"train\"].map(preprocess_function, remove_columns=[\"__index_level_0__\", \"date\", \"total_cases\", \"g_values\", \"created_at\", \"clean_tweets\"])\n",
        "    ds[\"validation\"] = ds[\"validation\"].map(preprocess_function, remove_columns=[\"__index_level_0__\", \"date\", \"total_cases\", \"g_values\", \"created_at\", \"clean_tweets\"])\n",
        "\n",
        "    train_dataloader = DataLoader(\n",
        "        ds[\"train\"], shuffle=False, batch_size=BATCH_SIZE, collate_fn=data_collator\n",
        "    )\n",
        "    eval_dataloader = DataLoader(\n",
        "        ds[\"validation\"], batch_size=BATCH_SIZE, collate_fn=data_collator\n",
        "    )\n",
        "else:\n",
        "    ds[\"test\"] = ds[\"test\"].map(preprocess_function, remove_columns=[\"__index_level_0__\", \"date\", \"total_cases\", \"g_values\", \"created_at\", \"clean_tweets\"])\n",
        "\n",
        "    test_dataloader = DataLoader(\n",
        "        ds[\"test\"], batch_size=BATCH_SIZE, collate_fn=data_collator\n",
        "    )\n",
        "\n",
        "# for split in ds:\n",
        "    # ds[split] = ds[split].map(preprocess_function, remove_columns=[\"__index_level_0__\", \"date\", \"total_cases\", \"g_values\", \"created_at\", \"clean_tweets\"])\n",
        "\n",
        "print(\"ds\")\n",
        "print(ds)\n",
        "\n",
        "for batch in train_dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    break\n",
        "print({k: v.shape for k, v in batch.items()})\n",
        "\n",
        "outputs = model(**batch)\n",
        "print(outputs.loss, outputs.logits.shape)\n",
        "\n",
        "def training():\n",
        "    num_training_steps = EPOCHS * len(train_dataloader)\n",
        "    lr_scheduler = get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=num_training_steps,\n",
        "    )\n",
        "    print(f\"num_training_steps: {num_training_steps}\")\n",
        "\n",
        "    from tqdm.auto import tqdm\n",
        "\n",
        "    progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(EPOCHS):\n",
        "        for batch_idx, batch in enumerate(train_dataloader):\n",
        "            print(f\"epoch: {epoch}, batch: {batch_idx}\")\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            # accelerator.backward(loss)\n",
        "\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "            progress_bar.update(1)\n",
        "\n",
        "def evaluation(dataloader):\n",
        "    eval_preds = []\n",
        "    eval_labels = []\n",
        "    model.eval()\n",
        "    for batch in dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "\n",
        "        print(f\"outputs['logits'].shape: {outputs['logits'].shape}\")\n",
        "        eval_preds.append(outputs['logits'])\n",
        "\n",
        "        print(f\"batch['labels'].shape: {batch['labels'].shape}\")\n",
        "        eval_labels.append(batch['labels'])\n",
        "\n",
        "    eval_preds = torch.cat(eval_preds, dim=0)\n",
        "    print(f\"eval_preds: {eval_preds}\")\n",
        "    eval_labels = torch.cat(eval_labels, dim=0)\n",
        "    print(f\"eval_labels: {eval_labels}\")\n",
        "    metrics = compute_metrics_for_regression(eval_preds, eval_labels)\n",
        "    print(metrics)\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "def compute_metrics_for_regression(eval_pred, eval_labels):\n",
        "    print(f\"eval_pred: {eval_pred}\")\n",
        "    print(f\"eval_labels: {eval_labels}\")\n",
        "    logits = eval_pred\n",
        "    labels = eval_labels\n",
        "    labels = torch.reshape(labels, (-1, 1))\n",
        "    print(f\"labels: {labels}\")\n",
        "\n",
        "    mse = mean_squared_error(labels.cpu(), logits.cpu())\n",
        "    mae = mean_absolute_error(labels.cpu(), logits.cpu())\n",
        "    r2 = r2_score(labels.cpu(), logits.cpu())\n",
        "    single_squared_errors = ((logits.cpu() - labels.cpu()).flatten()**2).tolist()\n",
        "\n",
        "    # Compute accuracy\n",
        "    # Based on the fact that the rounded score = true score only if |single_squared_errors| < 0.5\n",
        "    accuracy = sum([1 for e in single_squared_errors if e < 0.25]) / len(single_squared_errors)\n",
        "\n",
        "    return {\"mse\": mse, \"mae\": mae, \"r2\": r2, \"accuracy\": accuracy}\n",
        "\n",
        "if train:\n",
        "    ## TRAINING\n",
        "    t = time()\n",
        "\n",
        "    training()\n",
        "    evaluation(eval_dataloader)\n",
        "    model.save_pretrained(trained_model_name, from_pt=True)\n",
        "    tokenizer.save_pretrained(trained_model_name)\n",
        "\n",
        "    print('Time to train model: {} mins'.format(round((time() - t) / 60, 2)))\n",
        "\n",
        "else:\n",
        "    ## EVALUATION\n",
        "    t = time()\n",
        "    evaluation(test_dataloader)\n",
        "\n",
        "    print('Time to eval model: {} mins'.format(round((time() - t) / 60, 2)))"
      ]
    }
  ]
}